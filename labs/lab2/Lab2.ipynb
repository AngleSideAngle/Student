{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 Exploration: Color Images\n",
    "\n",
    "In this notebook, we will learn how to use the racecar camera to identify objects based on their color and extract the center and area of these objects.\n",
    "\n",
    "Throughout this notebook, **<font style=\"color:red\">text in bold red</font>** indicates a change you must make to the following code block before running it.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. [Getting Started](#GettingStarted)\n",
    "2. [Taking Photos](#TakingPhotos)\n",
    "3. [Color Formats](#ColorFormats)\n",
    "4. [Masks](#Masks)\n",
    "4. [Finding Contours](#FindingContours)\n",
    "4. [Contour Center](#ContourCenter)\n",
    "4. [Contour Area](#ContourArea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"GettingStarted\"></a>\n",
    "## 1. Getting Started\n",
    "\n",
    "**<font style=\"color:red\">If you are running the car in RacecarSim, set `isSimulation` to `True`</font>**. Leave `isSimulation` `False` if you are using a physical car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update isSimulation if necessary\n",
    "isSimulation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will import the necessary libraries for this notebook, including Python libraries (`cv`, `numpy`, etc.) and the Racecar library (`racecar_core`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from nptyping import NDArray\n",
    "from typing import Any, Tuple, List, Optional\n",
    "\n",
    "# Import Racecar library\n",
    "import sys\n",
    "sys.path.append(\"../../library\")\n",
    "import racecar_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will help us throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image: NDArray) -> None:\n",
    "    \"\"\"\n",
    "    Displays a color image in the Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def draw_contour(\n",
    "    image: NDArray,\n",
    "    contour: NDArray,\n",
    "    color: Tuple[int, int, int] = (0, 255, 0)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws a contour on the provided image.\n",
    "\n",
    "    Args:\n",
    "        image: The image on which to draw the contour.\n",
    "        contour: The contour to draw on the image.\n",
    "        color: The color to draw the contour in BGR format.\n",
    "    \"\"\"\n",
    "    cv.drawContours(image_copy, [contour], 0, color, 3)\n",
    "\n",
    "    \n",
    "def draw_circle(\n",
    "    color_image: NDArray[(Any, Any, 3), np.uint8],\n",
    "    center: Tuple[int, int],\n",
    "    color: Tuple[int, int, int] = (0, 255, 255),\n",
    "    radius: int = 6,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws a circle on the provided image.\n",
    "\n",
    "    Args:\n",
    "        color_image: The color image on which to draw the contour.\n",
    "        center: The pixel (row, column) of the center of the image.\n",
    "        color: The color to draw the circle in BGR format.\n",
    "        radius: The radius of the circle in pixels.\n",
    "    \"\"\"\n",
    "    # cv.circle expects the center in (column, row) format\n",
    "    cv.circle(color_image, (center[1], center[0]), radius, color, -1)\n",
    "\n",
    "    \n",
    "def show_color_bgr(blue: int, green: int, red: int) -> None:\n",
    "    \"\"\"\n",
    "    Displays a color specified in the BGR format.\n",
    "    \"\"\"\n",
    "    rectangle = plt.Rectangle((0,0), 50, 50, fc=(red/255, green/255, blue/255))\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_color_hsv(hue: int, saturation: int, value: int) -> None:\n",
    "    \"\"\"\n",
    "    Displays a color specified in the HSV format\n",
    "    \"\"\"\n",
    "    # Convert from hsv to bgr\n",
    "    hsv = np.array([[[hue, saturation, value]]], np.uint8)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    \n",
    "    show_color_bgr(bgr[0][0][0], bgr[0][0][1], bgr[0][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a racecar object.  If this step fails, make sure that `isSimulation` has the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Racecar\n",
    "rc = racecar_core.create_racecar(isSimulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TakingPhotos\"></a>\n",
    "## 2. Taking Photos\n",
    "In Jupyter Notebook, we can take a photo with the car's camera using `rc.camera.get_color_image_async()`.  Outside of Jupyter Notebook, we must use `rc.camera.get_color_image()` instead.\n",
    "\n",
    "Let's see what the car is currently looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take and display a photo\n",
    "image = rc.camera.get_color_image_async()\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color images are stored as three dimensional numpy arrays:\n",
    "\n",
    "* **0th dimension**: pixel rows, indexed from top to bottom.\n",
    "* **1st dimension**: pixel columns, indexed from left to right.\n",
    "* **2nd dimension**: pixel color values, ordered blue, green, red, each ranging from 0 (none of that color) to 255 (maximum amount of that color). \n",
    "\n",
    "Let's look at the color values of the middle pixel of our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate center row and column\n",
    "row = rc.camera.get_height() // 2\n",
    "col = rc.camera.get_width() // 2\n",
    "\n",
    "# Extract and print blue, green, and red values\n",
    "blue = image[row][col][0]\n",
    "green = image[row][col][1]\n",
    "red = image[row][col][2]\n",
    "\n",
    "print(\"blue:\", blue)\n",
    "print(\"green:\", green)\n",
    "print(\"red:\", red)\n",
    "\n",
    "# Display this color\n",
    "show_color_bgr(blue, green, red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Update `row` and `col` in the following code block to show the pixel that is is 2/3 from the top, 1/4 from the right.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the desired row and column \n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "# Extract and print blue, green, and red values\n",
    "blue = image[row][col][0]\n",
    "green = image[row][col][1]\n",
    "red = image[row][col][2]\n",
    "\n",
    "print(\"blue:\", blue)\n",
    "print(\"green:\", green)\n",
    "print(\"red:\", red)\n",
    "\n",
    "# Display this color\n",
    "show_color_bgr(blue, green, red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ColorFormats\"></a>\n",
    "## 3. Color Formats\n",
    "By default, the images captured by the camera are stored in the blue-green-red (BGR) format.  However, when recognizing objects based on their color, it is far easier to use the hue-saturation-value (HSV) format, in which each channel corresponds to the following:\n",
    "\n",
    "* **Hue** (0 to 180): The color as it appears on a color wheel, ordered as red-orange-yellow-green-blue-purple-red\n",
    "* **Saturation** (0 to 255): The amount of white added to the color.  0 is pure white, and 255 is the pure color without any white added.\n",
    "* **Value** (0 to 255): The amount of black added to the color.  0 is pure black, and 255 is the pure color without any black added.\n",
    "\n",
    "While saturation and value vary with lighting, hue will remain mostly the same regardless of lighting.  By focusing on the hue of the object we are attempting to detect, we can find it even in different lighting environments.\n",
    "\n",
    "We can use the following widgets to expiriment with different color values in the BGR and HSV formats.  **<font style=\"color:red\">For both formats, find the values which produce the following colors: orange, pink, dark green, yellow, and gray.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BGR color\n",
    "widgets.interact(show_color_bgr,\n",
    "                 blue=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
    "                 green=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
    "                 red=widgets.IntSlider(0, 0, 255, continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HSV color\n",
    "widgets.interact(show_color_hsv,\n",
    "                 hue=widgets.IntSlider(0, 0, 180, continuous_update=False),\n",
    "                 saturation=widgets.IntSlider(255, 0, 255, continuous_update=False),\n",
    "                 value=widgets.IntSlider(255, 0, 255, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Masks\"></a>\n",
    "## 4. Masks\n",
    "Lets work on identifying an object in the car's field of view based on its color.  Specifically, we will isolate the portions of an image which fall within a certain color range by defining upper and lower HSV bounds.  We will use that to create a *mask* - a special type of image which is white in areas to include and black in areas not to include.\n",
    "\n",
    "**<font style=\"color:red\">Finish writting the function `get_mask` below, which takes an image and returns a mask of the areas between hsv_lower and hsv_upper.</font>**  You will likely wish to use the following OpenCV functions:\n",
    "\n",
    "* [`cvtColor`](https://docs.opencv.org/4.2.0/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab): Converts an image from one color format to another, such as from BGR to HSV.\n",
    "* [`inRange`](https://docs.opencv.org/4.2.0/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981): Creates a mask from an image based on a lower and upper color bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(\n",
    "    image: NDArray[(Any, Any, 3), np.uint8],\n",
    "    hsv_lower: Tuple[int, int, int],\n",
    "    hsv_upper: Tuple[int, int, int]\n",
    ") -> NDArray[Any, Any]:\n",
    "    \"\"\"   \n",
    "    Returns a mask containing all of the areas of image which were between hsv_lower and hsv_upper.\n",
    "    \n",
    "    Args:\n",
    "        image: The image (stored in BGR) from which to create a mask.\n",
    "        hsv_lower: The lower bound of HSV values to include in the mask.\n",
    "        hsv_upper: The upper bound of HSV values to include in the mask.\n",
    "    \"\"\"\n",
    "    # Convert hsv_lower and hsv_upper to numpy arrays so they can be used by OpenCV\n",
    "    hsv_lower = np.array(hsv_lower)\n",
    "    hsv_upper = np.array(hsv_upper)\n",
    "    \n",
    "    # TODO: Use the cv.cvtColor function to switch our BGR colors to HSV colors\n",
    "    \n",
    "    # TODO: Use the cv.inRange function to highlight areas in the correct range\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `get_mask` to isolate a cone in an image.  Place a cone in the car's line of sight and take a picture with the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = rc.camera.get_color_image_async()\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the `get_mask` function to create a mask containing just the cone.  At the moment, `hsv_lower` and `hsv_upper` include all possible HSV values, so the mask will contain the entire image.  **<font style=\"color:red\">Tune the values of `hsv_lower` and `hsv_upper` until the mask only includes the cone.</font>**\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "* Use the HSV color widget from [Color Formats](#ColorFormats) to visualize HSV colors.\n",
    "* Copy the image into an image editing software (gimp, paint, etc.) and use the eyedrop tool to show the HSV values of the pixels in the cone.\n",
    "* Saturation and value vary a lot with lighting, but hue will remain mostly constant for a given object. Try using a wide range for value and saturation but a tight range for hue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_lower = (0, 50, 50)\n",
    "hsv_upper = (20, 255, 255)\n",
    "\n",
    "mask = get_mask(image, hsv_lower, hsv_upper)\n",
    "show_image(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this mask as a filter for our original image to only keep portions that were between `hsv_lower` and `hsv_upper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = cv.bitwise_and(image, image, mask=mask)\n",
    "show_image(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FindingContours\"></a>\n",
    "## 5. Finding Contours\n",
    "\n",
    "Now that we have a mask, we can create outlines called _contours_ around each object in the mask.  We will use these outlines to identify the largest object and calculates its size and position.\n",
    "\n",
    "First, we will use the OpenCV function [`findContours`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0) to create a list of contours around each distinct object in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(mask: NDArray) -> List[NDArray]:\n",
    "    \"\"\"\n",
    "    Returns a list of contours around all objects in a mask.\n",
    "    \"\"\"\n",
    "    return cv.findContours(mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_contours` will return a list containing multiple contours if there are multiple distinct objects which fall between `hsv_lower` and `hsv_upper`.  This might occur if there are multiple cones in the image or if there are other objects that have a similar color to the cone.\n",
    "\n",
    "Let's write a helper function to identify the largest contour, which we will assume is the closest cone.  This helper function should also ignore contours below a minimum size (such as `30 pixels`), since anything below this size is likely too small to be our cone.\n",
    "\n",
    "**<font style=\"color:red\">Finish writing `get_largest_contour` so that it returns the largest contour larger than `min_area`, or `None` if no such contour exists.</font>**  You will likely wish to use the OpenCV [`contourArea`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1) function to find the number of pixels in a contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_contour(contours: List[NDArray], min_area: int = 30) -> Optional[NDArray]:\n",
    "    \"\"\"\n",
    "    Finds the largest contour with size greater than min_area.\n",
    "\n",
    "    Args:\n",
    "        contours: A list of contours found in an image.\n",
    "        min_area: The smallest contour to consider (in number of pixels)\n",
    "\n",
    "    Returns:\n",
    "        The largest contour from the list, or None if no contour was larger than min_area.\n",
    "    \"\"\"\n",
    "    if len(contours) == 0:\n",
    "        # TODO: What should we return if the list of contours is empty?\n",
    "\n",
    "    \n",
    "    # TODO: Return the largest contour, but return None if no contour is larger than min_area\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out.  The following code block uses `find_contours` and `get_largest_contour` to find the largest contour and draw it on the image.  You should now see a green outline surrounding the closest cone in your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the largest contour\n",
    "contours = find_contours(mask)\n",
    "largest_contour = get_largest_contour(contours)\n",
    "\n",
    "# Draw it on the image\n",
    "image_copy = np.copy(image)\n",
    "draw_contour(image_copy, largest_contour)\n",
    "show_image(image_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ContourCenter\"></a>\n",
    "## 6. Contour Center\n",
    "\n",
    "One advantage of contours is that we can use them to easily calculate the center of an object.  Specifically, we will use the contour's [_Moments_](https://en.wikipedia.org/wiki/Image_moment), which are weighted averages of the pixels in the contour.  We can calculate the moment $M_{ij}$ with the following formula:\n",
    "\n",
    "```\n",
    "def moment(i, j):\n",
    "    sum = 0\n",
    "    for pixel in contour:\n",
    "        sum += pixel.x_position ** i + pixel.y_position ** j\n",
    "    return sum\n",
    "```\n",
    "\n",
    "To calculate contour center, we will use the following moments:\n",
    "\n",
    "* $M_{00}$: The number of pixels in the contour.\n",
    "* $M_{10}$: The sum of how far to the right each pixel in the contour is.\n",
    "* $M_{01}$: The sum of how far down each pixel in the contour is.\n",
    "\n",
    "Using the [center of mass equation](https://en.wikipedia.org/wiki/Center_of_mass), $\\frac{M['m10']}{M['m00']}$ gives us the average horizontal position (column) of the contour, and $\\frac{M['m01']}{M['m00']}$ gives us the average vertical position (row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_center(contour: NDArray) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Finds the center of a contour from an image.\n",
    "\n",
    "    Args:\n",
    "        contour: The contour of which to find the center.\n",
    "\n",
    "    Returns:\n",
    "        The (row, column) of the pixel at the center of the contour, or None if the contour is empty.\n",
    "    \"\"\"\n",
    "    # Ask OpenCV to calculate the contour's moments\n",
    "    M = cv.moments(contour)\n",
    "\n",
    "    # Check that the contour is not empty\n",
    "    if M[\"m00\"] <= 0:\n",
    "        return None\n",
    "\n",
    "    # Compute the center of mass of the contour\n",
    "    center_row = round(M[\"m01\"] / M[\"m00\"])\n",
    "    center_column = round(M[\"m10\"] / M[\"m00\"])\n",
    "    \n",
    "    return (center_row, center_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if this worked, we will draw a dot at this calculated center point. You should now see a yellow dot at the center of the cone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "center = get_contour_center(largest_contour)\n",
    "\n",
    "# Draw a circle at the contour center\n",
    "draw_circle(image_copy, center)\n",
    "show_image(image_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ContourArea\"></a>\n",
    "## 7. Contour Area\n",
    "\n",
    "When writing `get_largest_contour`, you likely used the OpenCV [`contourArea`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1) function.  Contour area is also helpful for calculating how far an object is from the camera, since the closer an object is, the more pixels it will take up on the screen.\n",
    "\n",
    "In this final section, we will measure the area of the cone at different distances from the car. Using previous examples from this notebook, **<font style=\"color:red\">update the following code block to take a photo, find the largest contour, print the contour area, and display the image with the contour.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Take a photo\n",
    "\n",
    "# TODO: Find the largest contour\n",
    "\n",
    "# TODO: Calculate and print the largest contour's area\n",
    "\n",
    "# TODO: Display the image with the contour drawn on top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font style=\"color:red\">Calculate the cone contour area when the cone is the following distances away from the car: 40 cm, 80 cm, 120 cm, 160 cm, 200 cm.  Update the entries in `data` with your results.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapoints in the format (cone distance from car in cm, number of pixels in contour)\n",
    "# TODO: Fill is contour area (currently 0)\n",
    "data = [\n",
    "    (40, 0),\n",
    "    (80, 0),\n",
    "    (120, 0),\n",
    "    (160, 0),\n",
    "    (200, 0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot this data to see the relationship between distance and cone area.  **How would you describe this relationship?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data in a scatter plot \n",
    "data_t = np.transpose(data)\n",
    "plt.scatter(data_t[0], data_t[1])\n",
    "plt.title(\"Relationship between Distance and Contour Area\")\n",
    "plt.xlabel(\"Cone distance (cm)\")\n",
    "plt.ylabel(\"Contour area (pixels)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to begin using the color camera to follow lines in `lab2a.py`. Good luck, and don't be afraid to ask questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
