{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Following Lab\n",
    "\n",
    "As described in the presentation, this lab will be all about line following. But, before we can follow lines, we need to write the code to do the image masking necessary to find the lines.\n",
    "\n",
    "First, we have included some helper functions below just to do some of the very simple tasks involving the camera. We ask that you use these for this notebook as using the underlying libraries incorrectly can cause the camera to become innaccessible until it is restarted. When you are using the car you will use the racecar_core equivalent of take_photo and again will not need to use opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROS imports\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../library\")\n",
    "import racecar_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init ROS node\n",
    "\n",
    "rospy.init_node(\"notebook\")\n",
    "rc = racecar_core.Racecar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def crop(image, top_left, bottom_right):\n",
    "    '''\n",
    "    image: an image (these are stored as arrays, top left is (0,0))\n",
    "    top_left: a pair of numbers representing the top left coordinate\n",
    "    bottom_right: a pair of numbers representing the bottom right coordinate\n",
    "\n",
    "    Helper function to make cropping images easier\n",
    "    \n",
    "    returns: a cropped version of the image\n",
    "    '''\n",
    "    x1, y1 = top_left\n",
    "    x2, y2 = bottom_right\n",
    "    return image[x1:x2,y1:y2]\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "def take_photo():\n",
    "    '''\n",
    "    Takes enough photos to ensure the camera has had time to bootup\n",
    "    \n",
    "    returns: A photo from the camera\n",
    "    '''\n",
    "    return rc._get_image_async()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_photo(image):\n",
    "    '''\n",
    "    image: an image\n",
    "    \n",
    "    Displays image\n",
    "    \n",
    "    returns: nothing\n",
    "    '''\n",
    "    plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a photo to see what the car can see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"Lab2_notebook_helper.py\", line 17, in <module>\n",
      "    rospy.init_node(\"image_lab_helper_node\")\n",
      "  File \"/opt/ros/melodic/lib/python2.7/dist-packages/rospy/client.py\", line 336, in init_node\n",
      "    raise rospy.exceptions.ROSInitException(\"Failed to initialize time. Please check logs for additional details\")\n",
      "rospy.exceptions.ROSInitException: Failed to initialize time. Please check logs for additional details\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /home/racecar/opencv-4.1.0/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ab29d68de944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-53d2784c8c9f>\u001b[0m in \u001b[0;36mdisplay_photo\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     '''\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /home/racecar/opencv-4.1.0/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "image = take_photo()\n",
    "display_photo(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks\n",
    "\n",
    "We can see the cone and describe where it is, but the computer can't yet, so let's work on that. We are going to be using a technique that's called a color mask. We describe to the computer a range of color values we care about, and then find the parts of the image that have those colors.\n",
    "\n",
    "Usually, computers store colors as a set of three numbers describing the amount of blue, green, and red (BGR). But for the task we are going to do, it's easier to think about a color in terms of it's hue, saturation, and value (HSV).\n",
    "\n",
    "Hue here refers to what color it is, saturation refers to how intense the color is, and value refers to how dark or light the color is.\n",
    "\n",
    "We reccomend copying the images taken by the camera to your computer (right-click > copy) and using whatever image editing software is on your computer (paint, gimp, etc.) to see what different colors look like in HSV.\n",
    "\n",
    "We reccomend looking to the openCV documentation for specifics on how to do the different tasks. In particular, we have suggested a few functions we think will be helpful, lookup how to use them here: https://docs.opencv.org/trunk/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_mask(image, hsv_low, hsv_high):\n",
    "    '''\n",
    "    image: an image\n",
    "    hsv_low: three numbers representing the minimal hue, saturation, and value\n",
    "    hsv_high: three numbers representing the maximal hue, saturation, and value\n",
    "    \n",
    "    Using the ranges provided, converts the image to the HSV format then finds what in the image is in the range.\n",
    "\n",
    "    returns: an array representing where in the image was in the range (the mask)\n",
    "    '''\n",
    "    hsv_low = np.array(hsv_low)\n",
    "    hsv_high = np.array(hsv_high)\n",
    "    \n",
    "    #TODO: use the cvtColor function to switch our BGR colors to HSV colors\n",
    "    \n",
    "    #TODO: use the inRange function to highlight areas in the correct range\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def cvt_mask_to_image(mask):\n",
    "    '''\n",
    "    mask: an image mask\n",
    "    \n",
    "    Takes the mask (which is just a 2D array) and adds color channels\n",
    "    so that it can be displayed easily given our existing infrastructure\n",
    "    \n",
    "    returns: a black an white image that is white where the mask is present\n",
    "    '''\n",
    "    height, width = mask.shape\n",
    "    blank_image = np.ones((height, width, 3), dtype=np.uint8)*255\n",
    "    mask_image = cv2.bitwise_and(blank_image, blank_image, mask=mask)\n",
    "    \n",
    "    return mask_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see what this looks like, test out different ranges for your Hue, Saturation, and Value? Which ones seem to matter the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = get_mask(image,(0,0,0),(255,255,255))\n",
    "# This mask will capture everything in the image, can we refine that?\n",
    "\n",
    "mask_image = cvt_mask_to_image(mask)\n",
    "display_photo(mask_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use this mask as a filter to our original image to get a better look at how effective our mask is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image_color = cv2.bitwise_and(image, image, mask=mask)\n",
    "display_photo(mask_image_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contours\n",
    "\n",
    "The next step in our process is to find the outline of our object so that we can eventually find it's center. Thankfully there are prebuilt functions for doing this, we just have to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_contour(mask):\n",
    "    '''\n",
    "    mask: an image mask\n",
    "    \n",
    "    Get's the largest contour if it exists, else returns None\n",
    "    \n",
    "    returns: a contour\n",
    "    '''\n",
    "    MIN_CONTOUR_SIZE = 30\n",
    "    # Normally we would have you look this up\n",
    "    # But we are using an old version of the library so the documentation is wrong\n",
    "    _,contours,_ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = list()\n",
    "    for contour in contours:\n",
    "        #TODO: check if the contour is large enough, then add it to the end of our list\n",
    "        #The contourArea function might be helpful here\n",
    "    \n",
    "    if len(large_contours) == 0: return None\n",
    "    #TODO: If we get to this step we have at least one large contour, return it.\n",
    "    \n",
    "def draw_contour(image, contour):\n",
    "    '''\n",
    "    image: an image\n",
    "    contour: an image contour\n",
    "    \n",
    "    Helper function to draw a contour in green on an image and display it\n",
    "    \n",
    "    returns: an image\n",
    "    '''\n",
    "    return cv2.drawContours(np.copy(image), [contour], 0, (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test out what you just wrote! Run the code below to draw the largest contour based on our image mask from above onto our original image. This should outline your cone! It's okay if it's not perfect, but it needs to capture where the cone is on your screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_photo(draw_contour(image, get_contour(mask)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find the middle of the cone from this contour, as this will help us to follow lines later on. The code below is written for you because you aren't expected to be able to replicate it on your own, but we will still describe what it means.\n",
    "\n",
    "We are finding what are called \"Moments\" of the contour. This is just math speak for certain information summarising the contour. For example $M['m00']$ is just how big the contour is, or it's area (we used a different function to get the same information earlier). $M['m10']$ is a sum of how far to the right each point is, over all points, and $M['m01']$ is the same, but how far down. So if a point inside of our contour has position $(3,5)$, it would contribute 3 to the first sum and 5 to the second. Thats why $M['m10']/M['m00']$ gives us the <em>average</em> horizontal position of the contour, and $M['m01']/M['m00']$ gives us the <em>average</em> vertical position, and so we have the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center(contour):\n",
    "    '''\n",
    "    contour: an image contour\n",
    "    \n",
    "    Find the center of the contour\n",
    "    \n",
    "    returns: an integer coordinate\n",
    "    '''\n",
    "    M = cv2.moments(contour)\n",
    "    if M['m00'] == 0: # No pixels\n",
    "        return None\n",
    "    contour_center_horizontal = M['m10']/M['m00']\n",
    "    contour_center_vertical = M['m01']/M['m00']\n",
    "    return (int(contour_center_horizontal), int(contour_center_vertical))\n",
    "\n",
    "def draw_dot(image, center):\n",
    "    '''\n",
    "    image: an array representing an image\n",
    "    center: an integer \n",
    "    \n",
    "    Helper function to draw an image with a blue dot in a specific location\n",
    "    \n",
    "    returns: an image\n",
    "    '''\n",
    "    return cv2.circle(np.copy(image), center, 2, (255,0,0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if it makes sense, we draw our dot on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_photo(draw_dot(image, find_center(get_contour(mask))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Now we'll put them both together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = get_contour(mask)\n",
    "display_photo(draw_dot(draw_contour(image, contour),find_center(contour)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! You are ready to tackle your line following lab! Take what you learned above and apply it to following the line. Don't forget to test for things like camera offset when you are figuring out your robot.\n",
    "\n",
    "We recomend that you use this notebook to figure out what color mask(s) work well for the color(s) you are trying to follow. Feel free to ask us for some tape and setup your own lines to test on the ground or out in the hall.\n",
    "\n",
    "If you finish early, think about how you might have your car follow multiple colors, or prioritize some colors over others.\n",
    "\n",
    "Don't be afraid to ask questions, good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
